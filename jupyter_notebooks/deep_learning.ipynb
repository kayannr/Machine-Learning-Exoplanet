{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\kayan\\anaconda3\\lib\\site-packages (0.21.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\kayan\\anaconda3\\lib\\site-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\kayan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\kayan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.16.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\kayan\\anaconda3\\lib\\site-packages (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install scikit-learn \n",
    "!pip install scikit-learn --upgrade\n",
    "!conda update scikit-learn\n",
    "!pip install joblib \n",
    "!pip install joblib --upgrade\n",
    "!pip update joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'datasets/exoplanet_data.csv' does not exist: b'datasets/exoplanet_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ddcc4ae3b24d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datasets/exoplanet_data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Drop the null columns where all values are null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'columns'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Drop the null rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'datasets/exoplanet_data.csv' does not exist: b'datasets/exoplanet_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            CONFIRMED\n",
       "1       False_Positive\n",
       "2       False_Positive\n",
       "3            CONFIRMED\n",
       "4            CONFIRMED\n",
       "             ...      \n",
       "6986    False_Positive\n",
       "6987    False_Positive\n",
       "6988         CANDIDATE\n",
       "6989    False_Positive\n",
       "6990    False_Positive\n",
       "Name: koi_disposition, Length: 6991, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Cleaning: Remove Space for `FALSE POSITIVE` category\n",
    "mask = df[\"koi_disposition\"] == \"FALSE POSITIVE\"\n",
    "df.loc[mask, \"koi_disposition\"] = \"False_Positive\"\n",
    "df[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df[\"koi_disposition\"]\n",
    "X = df.drop(columns=[\"koi_disposition\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99.673478</td>\n",
       "      <td>3.463000e-04</td>\n",
       "      <td>-3.463000e-04</td>\n",
       "      <td>219.334830</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>...</td>\n",
       "      <td>-148</td>\n",
       "      <td>4.777</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>293.05801</td>\n",
       "      <td>45.248821</td>\n",
       "      <td>15.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.592244</td>\n",
       "      <td>9.000000e-08</td>\n",
       "      <td>-9.000000e-08</td>\n",
       "      <td>131.654831</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>...</td>\n",
       "      <td>-146</td>\n",
       "      <td>4.664</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>290.28094</td>\n",
       "      <td>45.464260</td>\n",
       "      <td>15.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.991625</td>\n",
       "      <td>5.360000e-06</td>\n",
       "      <td>-5.360000e-06</td>\n",
       "      <td>137.447816</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.338</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>1.096</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>301.04239</td>\n",
       "      <td>45.022888</td>\n",
       "      <td>14.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3953</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178.412990</td>\n",
       "      <td>3.100000e-05</td>\n",
       "      <td>-3.100000e-05</td>\n",
       "      <td>218.225235</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>...</td>\n",
       "      <td>-134</td>\n",
       "      <td>4.346</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>288.32785</td>\n",
       "      <td>38.627621</td>\n",
       "      <td>13.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2362</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.294223</td>\n",
       "      <td>5.600000e-05</td>\n",
       "      <td>-5.600000e-05</td>\n",
       "      <td>138.678725</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>...</td>\n",
       "      <td>-68</td>\n",
       "      <td>4.347</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>1.044</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>285.67938</td>\n",
       "      <td>50.241299</td>\n",
       "      <td>10.961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "4002              0              0              1              0   99.673478   \n",
       "4246              0              1              0              0    0.592244   \n",
       "548               0              1              1              0    9.991625   \n",
       "3953              0              1              0              0  178.412990   \n",
       "2362              0              0              0              0   45.294223   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "4002     3.463000e-04    -3.463000e-04   219.334830          0.002300   \n",
       "4246     9.000000e-08    -9.000000e-08   131.654831          0.000124   \n",
       "548      5.360000e-06    -5.360000e-06   137.447816          0.000445   \n",
       "3953     3.100000e-05    -3.100000e-05   218.225235          0.000127   \n",
       "2362     5.600000e-05    -5.600000e-05   138.678725          0.000987   \n",
       "\n",
       "      koi_time0bk_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "4002         -0.002300  ...            -148      4.777           0.040   \n",
       "4246         -0.000124  ...            -146      4.664           0.056   \n",
       "548          -0.000445  ...            -176      4.338           0.153   \n",
       "3953         -0.000127  ...            -134      4.346           0.084   \n",
       "2362         -0.000987  ...             -68      4.347           0.030   \n",
       "\n",
       "      koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "4002          -0.027     0.492          0.026         -0.027  293.05801   \n",
       "4246          -0.032     0.591          0.045         -0.045  290.28094   \n",
       "548           -0.187     1.096          0.309         -0.206  301.04239   \n",
       "3953          -0.126     1.148          0.202         -0.124  288.32785   \n",
       "2362          -0.030     1.044          0.057         -0.042  285.67938   \n",
       "\n",
       "            dec  koi_kepmag  \n",
       "4002  45.248821      15.801  \n",
       "4246  45.464260      15.653  \n",
       "548   45.022888      14.039  \n",
       "3953  38.627621      13.944  \n",
       "2362  50.241299      10.961  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using LabelEncoder and MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5243, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shape \n",
    "y_train_categorical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=40))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 14,503\n",
      "Trainable params: 14,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      " - 0s - loss: 0.5587 - acc: 0.7276\n",
      "Epoch 2/60\n",
      " - 0s - loss: 0.3709 - acc: 0.8034\n",
      "Epoch 3/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kayan\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.3539 - acc: 0.8205\n",
      "Epoch 4/60\n",
      " - 0s - loss: 0.3484 - acc: 0.8156\n",
      "Epoch 5/60\n",
      " - 0s - loss: 0.3343 - acc: 0.8343\n",
      "Epoch 6/60\n",
      " - 0s - loss: 0.3281 - acc: 0.8432\n",
      "Epoch 7/60\n",
      " - 0s - loss: 0.3217 - acc: 0.8505\n",
      "Epoch 8/60\n",
      " - 0s - loss: 0.3167 - acc: 0.8549\n",
      "Epoch 9/60\n",
      " - 0s - loss: 0.3157 - acc: 0.8545\n",
      "Epoch 10/60\n",
      " - 0s - loss: 0.3065 - acc: 0.8589\n",
      "Epoch 11/60\n",
      " - 0s - loss: 0.3078 - acc: 0.8594\n",
      "Epoch 12/60\n",
      " - 0s - loss: 0.3036 - acc: 0.8604\n",
      "Epoch 13/60\n",
      " - 0s - loss: 0.3045 - acc: 0.8611\n",
      "Epoch 14/60\n",
      " - 0s - loss: 0.3006 - acc: 0.8591\n",
      "Epoch 15/60\n",
      " - 0s - loss: 0.2949 - acc: 0.8663\n",
      "Epoch 16/60\n",
      " - 0s - loss: 0.2944 - acc: 0.8676\n",
      "Epoch 17/60\n",
      " - 0s - loss: 0.2885 - acc: 0.8695\n",
      "Epoch 18/60\n",
      " - 0s - loss: 0.2861 - acc: 0.8732\n",
      "Epoch 19/60\n",
      " - 0s - loss: 0.2828 - acc: 0.8753\n",
      "Epoch 20/60\n",
      " - 0s - loss: 0.2815 - acc: 0.8743\n",
      "Epoch 21/60\n",
      " - 0s - loss: 0.2760 - acc: 0.8798\n",
      "Epoch 22/60\n",
      " - 0s - loss: 0.2719 - acc: 0.8791\n",
      "Epoch 23/60\n",
      " - 0s - loss: 0.2715 - acc: 0.8812\n",
      "Epoch 24/60\n",
      " - 0s - loss: 0.2705 - acc: 0.8795\n",
      "Epoch 25/60\n",
      " - 0s - loss: 0.2784 - acc: 0.8737\n",
      "Epoch 26/60\n",
      " - 0s - loss: 0.2700 - acc: 0.8821\n",
      "Epoch 27/60\n",
      " - 0s - loss: 0.2761 - acc: 0.8753\n",
      "Epoch 28/60\n",
      " - 0s - loss: 0.2645 - acc: 0.8840\n",
      "Epoch 29/60\n",
      " - 0s - loss: 0.2671 - acc: 0.8785\n",
      "Epoch 30/60\n",
      " - 0s - loss: 0.2631 - acc: 0.8850\n",
      "Epoch 31/60\n",
      " - 0s - loss: 0.2658 - acc: 0.8861\n",
      "Epoch 32/60\n",
      " - 0s - loss: 0.2600 - acc: 0.8871\n",
      "Epoch 33/60\n",
      " - 0s - loss: 0.2555 - acc: 0.8919\n",
      "Epoch 34/60\n",
      " - 0s - loss: 0.2658 - acc: 0.8838\n",
      "Epoch 35/60\n",
      " - 0s - loss: 0.2567 - acc: 0.8865\n",
      "Epoch 36/60\n",
      " - 0s - loss: 0.2565 - acc: 0.8859\n",
      "Epoch 37/60\n",
      " - 0s - loss: 0.2568 - acc: 0.8871\n",
      "Epoch 38/60\n",
      " - 0s - loss: 0.2518 - acc: 0.8901\n",
      "Epoch 39/60\n",
      " - 0s - loss: 0.2500 - acc: 0.8920\n",
      "Epoch 40/60\n",
      " - 0s - loss: 0.2472 - acc: 0.8936\n",
      "Epoch 41/60\n",
      " - 0s - loss: 0.2511 - acc: 0.8892\n",
      "Epoch 42/60\n",
      " - 0s - loss: 0.2504 - acc: 0.8924\n",
      "Epoch 43/60\n",
      " - 0s - loss: 0.2472 - acc: 0.8903\n",
      "Epoch 44/60\n",
      " - 0s - loss: 0.2452 - acc: 0.8930\n",
      "Epoch 45/60\n",
      " - 0s - loss: 0.2442 - acc: 0.8945\n",
      "Epoch 46/60\n",
      " - 0s - loss: 0.2449 - acc: 0.8953\n",
      "Epoch 47/60\n",
      " - 0s - loss: 0.2379 - acc: 0.8978\n",
      "Epoch 48/60\n",
      " - 0s - loss: 0.2410 - acc: 0.8936\n",
      "Epoch 49/60\n",
      " - 0s - loss: 0.2402 - acc: 0.8938\n",
      "Epoch 50/60\n",
      " - 0s - loss: 0.2443 - acc: 0.8932\n",
      "Epoch 51/60\n",
      " - 0s - loss: 0.2476 - acc: 0.8936\n",
      "Epoch 52/60\n",
      " - 0s - loss: 0.2399 - acc: 0.8966\n",
      "Epoch 53/60\n",
      " - 0s - loss: 0.2403 - acc: 0.8949\n",
      "Epoch 54/60\n",
      " - 0s - loss: 0.2423 - acc: 0.8932\n",
      "Epoch 55/60\n",
      " - 0s - loss: 0.2412 - acc: 0.8941\n",
      "Epoch 56/60\n",
      " - 0s - loss: 0.2360 - acc: 0.9022\n",
      "Epoch 57/60\n",
      " - 0s - loss: 0.2341 - acc: 0.8959\n",
      "Epoch 58/60\n",
      " - 0s - loss: 0.2447 - acc: 0.8936\n",
      "Epoch 59/60\n",
      " - 0s - loss: 0.2367 - acc: 0.8974\n",
      "Epoch 60/60\n",
      " - 0s - loss: 0.2403 - acc: 0.8957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d58d26848>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set early stopping as callback\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    callbacks=callbacks,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bc1fadfd0232>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model_loss, model_accuracy = model.evaluate(\n\u001b[0m\u001b[0;32m      2\u001b[0m     X_test_scaled, y_test_categorical, verbose=2)\n\u001b[0;32m      3\u001b[0m print(\n\u001b[0;32m      4\u001b[0m     f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['CANDIDATE' 'False_Positive' 'False_Positive' 'CANDIDATE'\n",
      " 'False_Positive']\n",
      "Actual Labels: ['CANDIDATE', 'False_Positive', 'False_Positive', 'CANDIDATE', 'False_Positive']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep_learning.sav']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save fitted model to file\n",
    "import joblib\n",
    "filename = 'deep_learning.sav'\n",
    "joblib.dump(model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
